import{t as f,a as v}from"../chunks/DKJMLC42.js";import"../chunks/BntcpoEZ.js";import{a,f as x,c as i,r as t,n as o}from"../chunks/BuAUvOro.js";import{h as s}from"../chunks/wXsJu9Ig.js";var u=f('<h1>Computational-Statistical Tradeoffs at the Next-Token Prediction Barrier: Autoregressive and Imitation Learning under Misspecification</h1> <p>Next token prediction withh log loss suffers from error amplification where errors compound and generation quality decreases as sequence length or horizon <span class="math math-inline"><!></span> gets large. Theoretically need not occur in well-specified (realizable) settings but it does in misspecified (agnostic) settings.</p> <p>Findings:</p> <ul><li>Info theoretically possible to avoide error amplification in immitation learning</li> <li>Next-token prediction (a special case of behavior cloning) achieves <span class="math math-inline"><!></span> multiplicative approximation error with best hypothesis.</li> <li>Autoregressive linear models can trade statistical power for compute.</li></ul> <h1>Next token prediciton</h1> <div class="math math-display"><!></div>',1);function _(h){var r=u(),e=a(x(r),2),m=a(i(e)),d=i(m);s(d,()=>'<span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>H</mi></mrow><annotation encoding="application/x-tex">H</annotation></semantics></math></span>'),t(m),o(),t(e);var n=a(e,4),l=a(i(n),2),p=a(i(l)),g=i(p);s(g,()=>'<span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mi>h</mi><mi>e</mi><mi>t</mi><mi>a</mi><mo stretchy="false">(</mo><mi>H</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">Theta(H)</annotation></semantics></math></span>'),t(p),o(),t(l),o(2),t(n);var c=a(n,4),w=i(c);s(w,()=>'<span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>Ï€</mi></mrow><annotation encoding="application/x-tex">\\pi</annotation></semantics></math></span>'),t(c),v(h,r)}export{_ as component};
