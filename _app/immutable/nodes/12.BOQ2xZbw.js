import{t as R,a as T}from"../chunks/DKJMLC42.js";import"../chunks/BntcpoEZ.js";import{a as m,f as j,c as t,r as a,n as s}from"../chunks/BuAUvOro.js";import{h as e}from"../chunks/wXsJu9Ig.js";var z=R('<p>A Gaussian process (GP) is a stochastic process (a collection of random variables indexed by time or space), such that every finite collection of those random variables has a multivariate normal distribution (copied from <a href="https://en.wikipedia.org/wiki/Gaussian_process#:~:text=a%20Gaussian%20process%20is%20a%20stochastic%20process%20(a%20collection%20of%20random%20variables%20indexed%20by%20time%20or%20space)%2C%20such%20that%20every%20finite%20collection%20of%20those%20random%20variables%20has%20a%20multivariate%20normal%20distribution." rel="nofollow">Wikipedia</a>).</p> <p>Some GPs (specifically stationary GPs, meaning it has a constant mean and covariance only depends on relative position of data points), have an explicit representation, where you can write it as</p> <div class="math math-display"><!></div> <p>for some random variables <span class="math math-inline"><!></span> and some fixed deterministic function <span class="math math-inline"><!></span> (I think this is true).</p> <h1>Bayesian inference and prediction with a GP</h1> <p>We have a training set <span class="math math-inline"><!></span>, and we wish to make a Bayesian prediction (see my notes on <a href="/digitalGarden/bayesianStuff">Bayesian stuff</a> for the difference between Bayesian inference and prediction) on a test sample <span class="math math-inline"><!></span> using our GP, which is a distribution over functions.</p> <p>We consider the following noise model, <span class="math math-inline"><!></span>, where <span class="math math-inline"><!></span>.</p> <p>Our joint prior on labels is</p> <div class="math math-display"><!></div> <p>From here, you just do the standard conditioning a joint Gaussian stuff (<a href="https://en.wikipedia.org/wiki/Multivariate_normal_distribution#Bayesian_inference:~:text=Conditional%20distributions" rel="nofollow">Wikipedia page for this</a>). Then you can write this as a new GP. This is your posterior predictive.</p> <p>You can place a GP prior over functions and then compute the posterior after seeing data to have some probability distribution for what the rest of the functin looks like. This is what they call Gaussian process regression. They get these cool visualizations from it like this from on <a href="https://scikit-learn.org/stable/modules/gaussian_process.html" rel="nofollow">scikit-learn</a>. <img src="/images/digitalGarden/coolGPReg.png" alt="Cool GP Regression" title="Cool GP Regression"></p> <p>But also, the argmax sample from the posterior predictive corresponds to the kernel ridge regression solution,</p> <div class="math math-display"><!></div> <p>where <span class="math math-inline"><!></span> is your ridge penalty / noise. This is just the mean solution in the plot above, so if you don’t care about the uncertainty quantification just do this ^.</p> <p>TODO: Maybe an example with a linear kernel?</p>',1);function W(v){var f=z(),o=m(j(f),4),b=t(o);e(b,()=>'<span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mi>g</mi><mo stretchy="false">(</mo><mi>R</mi><mo separator="true">,</mo><mi>x</mi><mo stretchy="false">)</mo><mo separator="true">,</mo></mrow><annotation encoding="application/x-tex">f(x) = g(R, x),</annotation></semantics></math></span>'),a(o);var i=m(o,2),n=m(t(i)),_=t(n);e(_,()=>'<span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi></mrow><annotation encoding="application/x-tex">R</annotation></semantics></math></span>'),a(n);var y=m(n,2),M=t(y);e(M,()=>'<span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>g</mi></mrow><annotation encoding="application/x-tex">g</annotation></semantics></math></span>'),a(y),s(),a(i);var r=m(i,4),l=m(t(r)),k=t(l);e(k,()=>'<span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">D</mi><mo>=</mo><mo stretchy="false">{</mo><mo stretchy="false">(</mo><msup><mi>x</mi><mrow><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></msup><mo separator="true">,</mo><msup><mi>y</mi><mrow><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></msup><mo stretchy="false">)</mo><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><mo stretchy="false">(</mo><msup><mi>x</mi><mrow><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo></mrow></msup><mo separator="true">,</mo><msup><mi>y</mi><mrow><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo></mrow></msup><mo stretchy="false">)</mo><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\\mathcal{D} = \\{ (x^{(1)}, y^{(1)}), \\ldots, (x^{(n)}, y^{(n)}) \\}</annotation></semantics></math></span>'),a(l);var w=m(l,4),G=t(w);e(G,()=>'<span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span>'),a(w),s(),a(r);var p=m(r,2),c=m(t(p)),X=t(c);e(X,()=>'<span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>y</mi><mrow><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow></msup><mo>=</mo><mi>g</mi><mo stretchy="false">(</mo><msup><mi>x</mi><mrow><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow></msup><mo stretchy="false">)</mo><mo>+</mo><msup><mi>ϵ</mi><mrow><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow></msup></mrow><annotation encoding="application/x-tex">y^{(i)} = g(x^{(i)}) + \\epsilon^{(i)}</annotation></semantics></math></span>'),a(c);var u=m(c,2),K=t(u);e(K,()=>'<span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>ϵ</mi><mrow><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow></msup><mo>∼</mo><mi mathvariant="script">N</mi><mo stretchy="false">(</mo><mn>0</mn><mo separator="true">,</mo><msubsup><mi>σ</mi><mi>n</mi><mn>2</mn></msubsup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\\epsilon^{(i)} \\sim \\mathcal{N}(0, \\sigma_n^2)</annotation></semantics></math></span>'),a(u),s(),a(p);var h=m(p,4),L=t(h);e(L,()=>'<span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mrow><mo fence="true">[</mo><mtable rowspacing="0.16em" columnalign="center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mi>Y</mi></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mi>f</mi></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow><mo>∼</mo><mi mathvariant="script">N</mi><mo fence="false" stretchy="true" minsize="1.8em" maxsize="1.8em">(</mo><mrow><mo fence="true">[</mo><mtable rowspacing="0.16em" columnalign="center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>m</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>m</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow><mo separator="true">,</mo><mrow><mo fence="true">[</mo><mtable rowspacing="0.16em" columnalign="center center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>K</mi><mo stretchy="false">(</mo><mi>X</mi><mo separator="true">,</mo><mi>X</mi><mo stretchy="false">)</mo><mo>+</mo><msubsup><mi>σ</mi><mi>n</mi><mn>2</mn></msubsup><msub><mi>I</mi><mi>d</mi></msub><mtext> </mtext></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>K</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>X</mi><mo stretchy="false">)</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>K</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>X</mi><mo stretchy="false">)</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>K</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow><mo fence="false" stretchy="true" minsize="1.8em" maxsize="1.8em">)</mo><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">\\begin{bmatrix} Y \\\\ f \\end{bmatrix} \\sim \\mathcal{N} \\Big(\\begin{bmatrix} m(X) \\\\ m(x) \\end{bmatrix}, \\begin{bmatrix} K(X, X) + \\sigma_n^2 I_d \\ &amp; K(x, X) \\\\ K(x, X) &amp; K(x, x) \\end{bmatrix} \\Big).</annotation></semantics></math></span>'),a(h);var d=m(h,8),P=t(d);e(P,()=>'<span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mover accent="true"><mi>f</mi><mo>^</mo></mover><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mi>K</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>X</mi><mo stretchy="false">)</mo><mo stretchy="false">(</mo><mi>K</mi><mo stretchy="false">(</mo><mi>X</mi><mo separator="true">,</mo><mi>X</mi><mo stretchy="false">)</mo><mo>−</mo><msubsup><mi>σ</mi><mi>n</mi><mn>2</mn></msubsup><msub><mi>I</mi><mi>d</mi></msub><msup><mo stretchy="false">)</mo><mrow><mo>−</mo><mn>1</mn></mrow></msup><mi>Y</mi><mo separator="true">,</mo></mrow><annotation encoding="application/x-tex">\\hat{f}(x) = K(x, X) (K(X, X) - \\sigma_n^2 I_{d} )^{-1} Y,</annotation></semantics></math></span>'),a(d);var x=m(d,2),g=m(t(x)),B=t(g);e(B,()=>'<span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>σ</mi><mi>n</mi><mn>2</mn></msubsup></mrow><annotation encoding="application/x-tex">\\sigma_n^2</annotation></semantics></math></span>'),a(g),s(),a(x),s(2),T(v,f)}export{W as component};
