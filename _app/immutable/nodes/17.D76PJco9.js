import{n as K,a as u,t as v}from"../chunks/DKJMLC42.js";import"../chunks/BntcpoEZ.js";import{i as D,o as Q,t as O,a as t,c as l,r as d,g as m,m as N,s as W,f as ee,n as te}from"../chunks/BuAUvOro.js";import{s as k}from"../chunks/D8__v_G3.js";import{i as $}from"../chunks/DAMHlmQC.js";import{s as ae}from"../chunks/DKjmvMdP.js";import{e as q}from"../chunks/hqIbxRWK.js";import{p as f}from"../chunks/BIEbWpQy.js";import{M as x}from"../chunks/BLKplkQ7.js";function re(a,e,i,o,c){var s;D&&Q();var p=(s=e.$$slots)==null?void 0:s[i],r=!1;p===!0&&(p=e.children,r=!0),p===void 0||p(a,r?()=>o:o)}function ne(a,e,i){var o=a==null?"":""+a;return o===""?null:o}function ie(a,e,i,o,c,p){var r=a.__className;if(D||r!==i||r===void 0){var s=ne(i);(!D||s!==a.getAttribute("class"))&&(s==null?a.removeAttribute("class"):a.setAttribute("class",s)),a.__className=i}return p}var oe=K('<svg fill="none" stroke="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"></path></svg>');function E(a,e){let i=f(e,"rotated",8,!1),o=f(e,"className",8,"");var c=oe();O(()=>ie(c,0,`w-4 h-4 ml-1 transition-transform ${i()?"rotate-180":""} ${o()??""}`)),u(a,c)}var se=v('<div class="mt-2 pl-2 pr-2 border-l-2 border-olive ml-4"><pre class="mt-2 bg-gray-100 p-2 rounded text-xs overflow-x-auto"> </pre></div>'),le=v('<div class="mt-2 pl-2 pr-2 border-l-2 border-olive ml-4 bg-light-olive"><!></div>'),de=v('<div class="paper mb-4"><a class="font-bold"> </a> <p class="mt-0 mb-0 ml-4"> </p> <p class="mt-0 mb-0 ml-4"> </p> <button class="text-olive underline bg-transparent border-none p-0 m-0 ml-4 cursor-pointer flex items-center" type="button"><span> </span> <!></button> <!> <button class="text-olive underline bg-transparent border-none p-0 m-0 ml-4 cursor-pointer flex items-center" type="button"><span> </span> <!></button> <!></div>');function F(a,e){let i=f(e,"title",8),o=f(e,"link",8),c=f(e,"authors",8),p=f(e,"year",8),r=f(e,"venue",8,""),s=f(e,"rawBibtex",8),n=N(!1),h=N(!1);function _(){W(n,!m(n))}function B(){W(h,!m(h))}var y=de(),w=l(y),I=l(w,!0);d(w);var C=t(w,2),H=l(C);d(C);var P=t(C,2),R=l(P);d(P);var M=t(P,2),z=l(M),U=l(z,!0);d(z);var j=t(z,2);E(j,{get rotated(){return m(h)}}),d(M);var L=t(M,2);{var G=b=>{var g=se(),T=l(g),X=l(T,!0);d(T),d(g),O(()=>k(X,s())),u(b,g)};$(L,b=>{m(h)&&b(G)})}var S=t(L,2),A=l(S),Z=l(A,!0);d(A);var V=t(A,2);E(V,{get rotated(){return m(n)}}),d(S);var Y=t(S,2);{var J=b=>{var g=le(),T=l(g);re(T,e,"default",{}),d(g),u(b,g)};$(Y,b=>{m(n)&&b(J)})}d(y),O(()=>{ae(w,"href",o()),k(I,i()),k(H,`${c()??""}.`),k(R,`${r()??""}, ${p()??""}.`),k(U,m(h)?"Hide":"BibTeX"),k(Z,m(n)?"Hide":"Description and my thoughts")}),q("click",M,B),q("click",S,_),u(a,y)}var pe=v('<p>We study a teacher-student learning setup, where a "student" one layer neural network tries to approximate a fixed "teacher" one layer neural network. We analyze the population gradient flow dynamics in the previously unstudied setting with exactly and under-parameterization, even Hermite polynomial activation functions, and squared loss. In the toy model with 2 teacher neurons and 2 student neurons, we fully characterize all critical points. We identify "tight-balance" critical points which are frequently encountered in simulation and greatly slow down training. We prove that with favorable initialization, we avoid tight-balance critical points and converge to the global optimum. We extend tight-balance critical points and favorable initializations to the multi-neuron exact and under-parameterized regimes. Additionally, we compare dynamics under the squared loss to the simpler correlation loss and describe the loss landscape in the multi-neuron exact and under-parameterized regimes. Finally, we discuss potential implications our work could have for training neural networks with even activation functions.</p>'),ce=v("<p>The light bulb problem is a fundamental unsupervised learning problem about identifying correlations amidst noise. In this report, we explore an online formulation of the light bulb problem. In light of the fact that the known offline approaches to the problem require super-linear space, we develop a simple algorithm which can solve the online problem using <!> space in <!> rounds. We then provide an enhanced algorithm which can toggle a tradeoff between space and rounds: namely, for any <!>, one can solve the online lightbulb problem with <!> space and <!> rounds. This method can be extended to allow for constant space, at the expense of quadratic rounds. Finally, we prove relevant lower bounds for the problem.</p>"),ue=v("<p>This paper investigates the relationship between model capacity and the emergence of in-context learning under a simplified statistical framework in the transformer model. When model capacity is restricted enough, transformers shift from learning the Bayes optimal estimator for the training task distribution to an estimator that is suitable for out-of-distribution tasks. This shift is attributed to the restricted model's inability to fully memorize the training task distribution. Further experiments examine how the transformer's hyper-parameters impact its capacity for memorization.</p>"),he=v("<p>We first describe the type of RF impairments observable by PNM. We apply unsupervised learning methods to detect these impairments. We integrate our approach into CableLab's spectral impairment detector (SID) to substantially improve on SID's impairment classifiers. Finally, we consider how feedback from end users could enable a supervised learning approach.</p>"),me=v('<p class="mb-4">Updated May 10, 2025. See my <a href="https://scholar.google.com/citations?user=cAkhZCgAAAAJ">Google Scholar profile</a> for the most up-to-date record of my publications.</p> <!> <!> <!> <!>',1);function Be(a){var e=me(),i=t(ee(e),2);F(i,{title:"Gradient Flow Dynamics of Teacher-Student Distillation with the Squared Loss",link:"https://berkan.xyz/files/underparameterizedDynamics.pdf",authors:"Berkan Ottlik",year:"2024",venue:"Presented at the Summer@Simons poster session",rawBibtex:`@article{ottlik2024gradient,
  author = "Ottlik, Berkan",
  title = "Gradient Flow Dynamics of Teacher-Student Distillation with the Squared Loss",
  journal = "Presented at the Summer@Simons poster session",
  year = "2024",
  url = "https://berkan.xyz/files/underparameterizedDynamics.pdf"
}`,children:(r,s)=>{var n=pe();u(r,n)},$$slots:{default:!0}});var o=t(i,2);F(o,{title:"A Sequential Lightbulb Problem",link:"https://berkan.xyz/files/lightbulb.pdf",authors:"Noah Bergam, Berkan Ottlik, Arman Özcan",year:"2024",venue:"Presented at the Fall Fourier Talks, University of Maryland",rawBibtex:`@article{bergam2024sequential,
  author = "Bergam, Noah and Ottlik, Berkan and Özcan, Arman",
  title = "A Sequential Lightbulb Problem",
  journal = "Presented at the Fall Fourier Talks, University of Maryland",
  year = "2024",
  url = "https://berkan.xyz/files/lightbulb.pdf"
}`,children:(r,s)=>{var n=ce(),h=t(l(n));x(h,{latex:String.raw`O(n)`});var _=t(h,2);x(_,{latex:String.raw`\tilde{O}(n)`});var B=t(_,2);x(B,{latex:String.raw`\alpha \in (0,1)`});var y=t(B,2);x(y,{latex:String.raw`O(n^{1-\alpha})`});var w=t(y,2);x(w,{latex:String.raw`\tilde{O}(n^{1+\alpha})`}),te(),d(n),u(r,n)},$$slots:{default:!0}});var c=t(o,2);F(c,{title:"The Effect of Model Capacity on the Emergence of In-Context Learning",link:"https://openreview.net/pdf?id=YZM9g0Mi9a",authors:"Berkan Ottlik, Narutatsu Ri, Daniel Hsu, Clayton Sanford",year:"2024",venue:"ICLR 2024 Workshop on Understanding of Foundation Models (ME-FoMo)",rawBibtex:`@inproceedings{ottlik2024effect,
  author = "Ottlik, Berkan and Ri, Narutatsu and Hsu, Daniel and Sanford, Clayton",
  title = "The Effect of Model Capacity on the Emergence of In-Context Learning",
  booktitle = "ICLR 2024 Workshop on Understanding of Foundation Models (ME-FoMo)",
  year = "2024",
  url = "https://openreview.net/pdf?id=YZM9g0Mi9a"
}`,children:(r,s)=>{var n=ue();u(r,n)},$$slots:{default:!0}});var p=t(c,2);F(p,{title:"Machine Learning and Proactive Network Maintenance: Transforming Today's Plant Operations",link:"https://www.nctatechnicalpapers.com/Paper/2021/2021-machine-learning-and-proactive-network-maintenance-transforming-today-s-plant-operations/",authors:"Berkan Ottlik, Brady Volpe",year:"2021",venue:"Fall Technical Forum: SCTE, NCTA, CableLabs",rawBibtex:`@article{ottlik2021machine,
  author = "Ottlik, Berkan and Volpe, Brady",
  title = "Machine Learning and Proactive Network Maintenance: Transforming Today's Plant Operations",
  journal = "Fall Technical Forum: SCTE, NCTA, CableLabs",
  year = "2021",
  url = "https://www.nctatechnicalpapers.com/Paper/2021/2021-machine-learning-and-proactive-network-maintenance-transforming-today-s-plant-operations/"
}`,children:(r,s)=>{var n=he();u(r,n)},$$slots:{default:!0}}),u(a,e)}export{Be as component};
